{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Author: Addison Li \n",
    "- Date: 2019-03-17\n",
    "- Content: JPM filtering with curve fitting on Ticker, Sector, and S&P Rating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "\n",
    "pd.set_option('display.max_columns', 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_names(name_list):\n",
    "    col_names = []\n",
    "    for name in name_list:\n",
    "        t = name.lower()\n",
    "        if \" \" in t:\n",
    "            c_t = t.replace(' ',\"_\")\n",
    "        else:\n",
    "            c_t = t\n",
    "        col_names.append(c_t)\n",
    "    return col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_time(df1):\n",
    "    \n",
    "    copy = df1.iloc[:,0].apply(lambda x: None if len(x) <= 12 else x)\n",
    "    copy = copy.ffill()\n",
    "    \n",
    "    return copy\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\nThe first step of preparing the dataframe: \\n1. drop the na columns or rows after examnination \\n2. clean up column names \\n\\n\\ndef prep_df_1 (raw_df):\\n    temp = raw_df.dropna(axis = 1, how = 'all')\\n    names = temp.columns.tolist()\\n    col_names = clean_names(names)\\n    \\n    temp.columns = col_names\\n    \\n    # not the most ideal, but this way keeps the original idx in tact\\n    temp_2 = temp.dropna(axis = 0, thresh = 16)\\n    \\n    return temp_2\\n   \\n\\ndef prep_df_2(raw):\\n    df1 =  prep_df_1(raw) #(58324, 20)\\n    dates = fill_time(df1)\\n    df1.insert(0, column = 'dates', value = pd.Series(dates))\\n    df1 = df1.dropna() # (58308, 22)\\n    df2 = df1.reset_index()\\n    df3 = df2.drop(columns = ['index', 'unnamed:_0'], axis = 1)\\n    \\n    return df3\\n \\ndef clean_time(p2_df):\\n    from datetime import datetime\\n    \\n    start_date,end_date = p2_df['dates'].str.split('-', 1).str\\n    p2_df.insert(0,'start_date', start_date)\\n    p2_df.insert(1, 'end_date', end_date)\\n    \\n    p2_df.start_date = p2_df.start_date.apply(lambda x: datetime.strptime(x, '%m/%d/%Y'))\\n    p2_df.end_date = p2_df.end_date.apply(lambda x: datetime.strptime(x, '%m/%d/%Y'))\\n    \\n    p2_df.drop(labels = ['dates'], axis = 1, inplace = True)\\n    \\n    return p2_df\\n\\nclean_df = clean_time(p2_df)\\n\\n\""
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "The first step of preparing the dataframe: \n",
    "1. drop the na columns or rows after examnination \n",
    "2. clean up column names \n",
    "\n",
    "\n",
    "def prep_df_1 (raw_df):\n",
    "    temp = raw_df.dropna(axis = 1, how = 'all')\n",
    "    names = temp.columns.tolist()\n",
    "    col_names = clean_names(names)\n",
    "    \n",
    "    temp.columns = col_names\n",
    "    \n",
    "    # not the most ideal, but this way keeps the original idx in tact\n",
    "    temp_2 = temp.dropna(axis = 0, thresh = 16)\n",
    "    \n",
    "    return temp_2\n",
    "   \n",
    "\n",
    "def prep_df_2(raw):\n",
    "    df1 =  prep_df_1(raw) #(58324, 20)\n",
    "    dates = fill_time(df1)\n",
    "    df1.insert(0, column = 'dates', value = pd.Series(dates))\n",
    "    df1 = df1.dropna() # (58308, 22)\n",
    "    df2 = df1.reset_index()\n",
    "    df3 = df2.drop(columns = ['index', 'unnamed:_0'], axis = 1)\n",
    "    \n",
    "    return df3\n",
    " \n",
    "def clean_time(p2_df):\n",
    "    from datetime import datetime\n",
    "    \n",
    "    start_date,end_date = p2_df['dates'].str.split('-', 1).str\n",
    "    p2_df.insert(0,'start_date', start_date)\n",
    "    p2_df.insert(1, 'end_date', end_date)\n",
    "    \n",
    "    p2_df.start_date = p2_df.start_date.apply(lambda x: datetime.strptime(x, '%m/%d/%Y'))\n",
    "    p2_df.end_date = p2_df.end_date.apply(lambda x: datetime.strptime(x, '%m/%d/%Y'))\n",
    "    \n",
    "    p2_df.drop(labels = ['dates'], axis = 1, inplace = True)\n",
    "    \n",
    "    return p2_df\n",
    "\n",
    "clean_df = clean_time(p2_df)\n",
    "\n",
    "'''\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv('vanguard_merge.csv', thousands = ',', parse_dates = ['Mty','Iss Dt','date'])\n",
    "\n",
    "# raw.shape: (1541005, 27)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_col = clean_names(col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.columns = clean_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bclass3                     0\n",
       "country                     0\n",
       "bid_spread                  0\n",
       "cur_yld                     0\n",
       "g_spd                       0\n",
       "years_to_mat                0\n",
       "oas                         0\n",
       "oad                         0\n",
       "amt_out                     0\n",
       "cpn                         0\n",
       "excess_rtn                  0\n",
       "isin                        0\n",
       "ticker                      0\n",
       "mty                       268\n",
       "iss_dt                      0\n",
       "px_close                    0\n",
       "krd_6m                      0\n",
       "krd_2y                      0\n",
       "krd_5y                      0\n",
       "krd_10y                     0\n",
       "krd_20y                     0\n",
       "krd_30y                     0\n",
       "s&p_rating_num           9986\n",
       "accrued_int_(%)             0\n",
       "yield_to_mat                0\n",
       "class_-_detail_-_code     105\n",
       "date                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping missing data because there is 1 bond, missing 268 days of mty,\n",
    "# same for s&p rating, 9986 out of 1,541,005 is 0.6%. we can safely toss them out. \n",
    "df = raw.dropna()\n",
    "# shape: (1530646, 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bclass3</th>\n",
       "      <th>country</th>\n",
       "      <th>bid_spread</th>\n",
       "      <th>cur_yld</th>\n",
       "      <th>g_spd</th>\n",
       "      <th>years_to_mat</th>\n",
       "      <th>oas</th>\n",
       "      <th>oad</th>\n",
       "      <th>amt_out</th>\n",
       "      <th>cpn</th>\n",
       "      <th>excess_rtn</th>\n",
       "      <th>isin</th>\n",
       "      <th>ticker</th>\n",
       "      <th>mty</th>\n",
       "      <th>iss_dt</th>\n",
       "      <th>px_close</th>\n",
       "      <th>krd_6m</th>\n",
       "      <th>krd_2y</th>\n",
       "      <th>krd_5y</th>\n",
       "      <th>krd_10y</th>\n",
       "      <th>krd_20y</th>\n",
       "      <th>krd_30y</th>\n",
       "      <th>s&amp;p_rating_num</th>\n",
       "      <th>accrued_int_(%)</th>\n",
       "      <th>yield_to_mat</th>\n",
       "      <th>class_-_detail_-_code</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1359936</th>\n",
       "      <td>Consumer Non-Cyclical</td>\n",
       "      <td>United States</td>\n",
       "      <td>93.0</td>\n",
       "      <td>3.27</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.57</td>\n",
       "      <td>91.00</td>\n",
       "      <td>2.41</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>3.250</td>\n",
       "      <td>0.04</td>\n",
       "      <td>US98978VAQ68</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>2021-08-20</td>\n",
       "      <td>2018-08-20</td>\n",
       "      <td>99.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.390</td>\n",
       "      <td>3.50</td>\n",
       "      <td>BBDE</td>\n",
       "      <td>2019-01-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359937</th>\n",
       "      <td>Banking</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.94</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.49</td>\n",
       "      <td>72.85</td>\n",
       "      <td>2.39</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>1.875</td>\n",
       "      <td>0.00</td>\n",
       "      <td>XS1451467127</td>\n",
       "      <td>RABOBK</td>\n",
       "      <td>2021-07-19</td>\n",
       "      <td>2016-07-19</td>\n",
       "      <td>96.55</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.964</td>\n",
       "      <td>3.31</td>\n",
       "      <td>BAA</td>\n",
       "      <td>2019-01-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359938</th>\n",
       "      <td>Banking</td>\n",
       "      <td>S.Korea</td>\n",
       "      <td>169.0</td>\n",
       "      <td>3.92</td>\n",
       "      <td>168.0</td>\n",
       "      <td>2.87</td>\n",
       "      <td>168.39</td>\n",
       "      <td>2.67</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>3.875</td>\n",
       "      <td>0.07</td>\n",
       "      <td>XS1523140942</td>\n",
       "      <td>SHNHAN</td>\n",
       "      <td>2026-12-07</td>\n",
       "      <td>2016-12-07</td>\n",
       "      <td>98.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.506</td>\n",
       "      <td>4.27</td>\n",
       "      <td>BAA</td>\n",
       "      <td>2019-01-23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       bclass3        country  bid_spread  cur_yld  g_spd  \\\n",
       "1359936  Consumer Non-Cyclical  United States        93.0     3.27   91.0   \n",
       "1359937                Banking    Netherlands        73.0     1.94   73.0   \n",
       "1359938                Banking        S.Korea       169.0     3.92  168.0   \n",
       "\n",
       "         years_to_mat     oas   oad   amt_out    cpn  excess_rtn  \\\n",
       "1359936          2.57   91.00  2.41  300000.0  3.250        0.04   \n",
       "1359937          2.49   72.85  2.39  300000.0  1.875        0.00   \n",
       "1359938          2.87  168.39  2.67  500000.0  3.875        0.07   \n",
       "\n",
       "                 isin  ticker        mty     iss_dt  px_close  krd_6m  krd_2y  \\\n",
       "1359936  US98978VAQ68     ZTS 2021-08-20 2018-08-20     99.40    0.00    1.87   \n",
       "1359937  XS1451467127  RABOBK 2021-07-19 2016-07-19     96.55   -0.01    1.92   \n",
       "1359938  XS1523140942  SHNHAN 2026-12-07 2016-12-07     98.95    0.00    1.86   \n",
       "\n",
       "         krd_5y  krd_10y  krd_20y  krd_30y  s&p_rating_num  accrued_int_(%)  \\\n",
       "1359936    0.53      0.0      0.0      0.0            10.0            1.390   \n",
       "1359937    0.47      0.0      0.0      0.0             6.0            0.964   \n",
       "1359938    0.80      0.0      0.0      0.0             9.0            0.506   \n",
       "\n",
       "         yield_to_mat class_-_detail_-_code       date  \n",
       "1359936          3.50                  BBDE 2019-01-23  \n",
       "1359937          3.31                   BAA 2019-01-23  \n",
       "1359938          4.27                   BAA 2019-01-23  "
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.date == \"2019-01-23\"].tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorized version of calculating g_spd \n",
    "\n",
    "def mark_gspd_v(clean_df, today_date, isin_list):\n",
    "    \n",
    "    target_df = clean_df[clean_df['isin'].isin(isin_list)]\n",
    "\n",
    "    out_df = target_df[target_df.date == today_date][['isin', 'g_spd']]\n",
    "    out_df['g_min'] = target_df.groupby(['isin'])['g_spd'].min().values\n",
    "    out_df['g_max'] = target_df.groupby(['isin'])['g_spd'].max().values\n",
    "    out_df['delta'] = out_df.g_max - out_df.g_min\n",
    "   \n",
    "    # filter out the bonds with delta great than 10 base points \n",
    "\n",
    "    delta_df = out_df[out_df.delta >= 10] \n",
    "    c_filter = delta_df['g_spd'] > delta_df['g_min'] + delta_df['delta'].values*0.95\n",
    "    delta_df['cheap']= [1 if i == True else 0 for i in c_filter]\n",
    "\n",
    "    r_filter = delta_df['g_spd'] < delta_df['g_min'] + delta_df['delta'].values*0.05 \n",
    "    delta_df['rich']= [1 if i == True else 0 for i in r_filter]\n",
    "\n",
    "    return delta_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at the last month:  2019-02-07  to 2019-03-07\n",
    "\n",
    "one_month = df.iloc[1359938:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(one_month.date.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "today_date = '2019-03-07'\n",
    "today_df = one_month[one_month.date == today_date]\n",
    "isin_all = today_df['isin']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AddisonYing/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/AddisonYing/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# delta_df returns a dataframe that's filtered by 2 criterias:\n",
    "# 1) we are only look at the ones delta > 10 over the target period (30 / 60 days)\n",
    "# 2) g_spd exceeds top 95% or falls below the bottom 5%\n",
    "delta_df = mark_gspd_v(one_month, today_date, isin_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1050 expensive bonds.\n"
     ]
    }
   ],
   "source": [
    "# expensive bonds  \n",
    "expensive = delta_df[delta_df['rich'] == 1]\n",
    "\n",
    "print(\"There are\", expensive.shape[0], \"expensive bonds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 197 cheap bonds.\n"
     ]
    }
   ],
   "source": [
    "# cheap bonds - good\n",
    "cheap = delta_df[delta_df['cheap'] == 1]\n",
    "\n",
    "print(\"There are\", cheap.shape[0], \"cheap bonds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### look at individual bonds spread over 10 day time period. If this bond spread is trading at its widest(cheapest) 5% level, over the course of 10 day, mark this criteria \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the issuer curve\n",
    "- compare the spread against the issuer curve, which is just all the bonds within the same issuer and if that individual bond is trading wide to the issuer curve it meets another criteria\n",
    "- issuer curve, y-axis: g_spread , x-axis: years_to_ maturity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_groupby = one_month.groupby(['ticker', 'date','isin'])['g_spd', 'years_to_mat'].mean() # shape:(58314, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1729)\n",
    "\n",
    "def func(x, m, c):\n",
    "    return m*np.log(x)+ c \n",
    "\n",
    "def cal_curve(ticker_groupby):\n",
    "    \n",
    "    from scipy.optimize import curve_fit\n",
    "\n",
    "    tickers = pd.unique(ticker_groupby.index.get_level_values(0))\n",
    "    dates = pd.unique(ticker_groupby.index.get_level_values(1))\n",
    "    ticker_temp = ticker_groupby.reset_index()\n",
    "    \n",
    "    g_spd_pred =[]\n",
    "    diff = []\n",
    "    idx = []\n",
    "    \n",
    "    for t in tickers:\n",
    "        for d in dates:\n",
    "            temp = ticker_temp[ticker_temp['ticker'] == t]\n",
    "            sub_df = temp[temp['date'] == d]\n",
    "            \n",
    "            if sub_df.shape[0] >= 6:\n",
    "                sub_x = sub_df['years_to_mat'].values\n",
    "                sub_y = sub_df['g_spd'].values\n",
    "            \n",
    "                popt, pcov = curve_fit(func, sub_x, sub_y)\n",
    "                g_predict = func(sub_x, popt[0], popt[1])\n",
    "                sub_diff = g_predict - sub_y\n",
    "                g_spd_pred.append(g_predict)\n",
    "                diff.append(sub_diff)\n",
    "                idx.append(sub_df.index)\n",
    "            \n",
    "    g_pred = np.concatenate(g_spd_pred)\n",
    "    g_diff = np.concatenate(diff)\n",
    "    g_idx = np.concatenate(idx)\n",
    "    \n",
    "    return g_pred, g_diff, g_idx \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_pred_t, g_diff_t, g_idx_t = cal_curve(ticker_groupby)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ticker = ticker_groupby.iloc[g_idx_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AddisonYing/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "result_ticker['g_pred'] = g_pred_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AddisonYing/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "result_ticker['g_diff'] = g_diff_t  # result_df.shape : (54806, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "peer_df = result_ticker.reset_index() # peer_df.shape: (54806, 7), unique isin 5572\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140203, 7)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peer_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the total num of unique isins in the dataset is 5925 \n",
    "- after filtering the ones we cant fit the line with peers, there are 5572 unique isin in peer_df\n",
    "- the num of target date unique isin is 5832\n",
    "- the intersect between target date isin and peer isin is 5481\n",
    "- however, when we get all the peer isin info on the target date, we are missing 4 isins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_peer_filter(peer_df, target_isin, target_date):\n",
    "    \n",
    "    avail_isin = np.intersect1d(target_isin, peer_df['isin'].values) \n",
    "    \n",
    "    prep_self = peer_df[peer_df['isin'].isin(avail_isin)]\n",
    "    self_df = prep_self.groupby(['isin'])[['g_diff']].max().reset_index()\n",
    "    self_df.columns = ['isin', 'g_diff_max']\n",
    "    \n",
    "    self_df['g_diff_min'] = prep_self.groupby(['isin'])[['g_diff']].min().values\n",
    "    self_df['delta'] = self_df['g_diff_max'] - self_df['g_diff_min']\n",
    "    self_df['perc_95'] = self_df.g_diff_min + self_df.delta.values*0.95\n",
    "    self_df['bottom_5'] = self_df.g_diff_min + self_df.delta.values*0.05\n",
    "   \n",
    "    # making sure delta is >= 10\n",
    "    delta_10 = self_df[self_df['delta']>=10]\n",
    "    delta_isin = delta_10['isin'].values\n",
    "    sub_peer = peer_df[peer_df['isin'].isin(delta_isin)]\n",
    "    \n",
    "    target_diff = sub_peer[sub_peer['date'] == target_date][['isin', 'g_diff']]  #1429 rows × 7 columns\n",
    "    sub_self = self_df[self_df['isin'].isin(target_diff['isin'].values)]\n",
    "    \n",
    "    return target_diff, sub_self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(target_diff, sub_self):\n",
    "    c = target_diff['g_diff'].values - sub_self['perc_95'].values\n",
    "    cheap =[1 if diff >0 else 0 for diff in c] \n",
    "    sub_self['cheap'] = cheap\n",
    "    \n",
    "    r = target_diff['g_diff'].values - sub_self['bottom_5'].values\n",
    "    rich = [1 if diff < 0 else 0 for diff in r]\n",
    "    sub_self['rich']= rich\n",
    "    \n",
    "    sub_self['target_day'] = target_diff['g_diff'].values\n",
    "    \n",
    "    return sub_self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_date = \"2019-03-07\"\n",
    "target_isin = one_month[one_month['date'] == target_date]['isin'].values\n",
    "#len(target_isin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_diff, sub_self = self_peer_filter(peer_df, target_isin, target_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_final = get_results(target_diff, sub_self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isin</th>\n",
       "      <th>g_diff_max</th>\n",
       "      <th>g_diff_min</th>\n",
       "      <th>delta</th>\n",
       "      <th>perc_95</th>\n",
       "      <th>bottom_5</th>\n",
       "      <th>cheap</th>\n",
       "      <th>rich</th>\n",
       "      <th>target_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US001055AJ19</td>\n",
       "      <td>9.742960</td>\n",
       "      <td>-1.871478</td>\n",
       "      <td>11.614438</td>\n",
       "      <td>9.162238</td>\n",
       "      <td>-1.290756</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.099140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US001055AL64</td>\n",
       "      <td>14.656741</td>\n",
       "      <td>0.554859</td>\n",
       "      <td>14.101882</td>\n",
       "      <td>13.951647</td>\n",
       "      <td>1.259953</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.782996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US001055AM48</td>\n",
       "      <td>17.761705</td>\n",
       "      <td>-0.628311</td>\n",
       "      <td>18.390016</td>\n",
       "      <td>16.842204</td>\n",
       "      <td>0.291190</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.010219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>US00108WAD20</td>\n",
       "      <td>14.746628</td>\n",
       "      <td>0.342575</td>\n",
       "      <td>14.404053</td>\n",
       "      <td>14.026425</td>\n",
       "      <td>1.062777</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-13.939129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>US00108WAH34</td>\n",
       "      <td>6.722973</td>\n",
       "      <td>-6.687988</td>\n",
       "      <td>13.410961</td>\n",
       "      <td>6.052425</td>\n",
       "      <td>-6.017440</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.382505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>US001192AJ21</td>\n",
       "      <td>13.223852</td>\n",
       "      <td>-14.715790</td>\n",
       "      <td>27.939643</td>\n",
       "      <td>11.826870</td>\n",
       "      <td>-13.318808</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.692355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>US001192AK93</td>\n",
       "      <td>2.660700</td>\n",
       "      <td>-8.444020</td>\n",
       "      <td>11.104719</td>\n",
       "      <td>2.105464</td>\n",
       "      <td>-7.888784</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.071720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>US00185AAF12</td>\n",
       "      <td>23.268738</td>\n",
       "      <td>7.121001</td>\n",
       "      <td>16.147737</td>\n",
       "      <td>22.461351</td>\n",
       "      <td>7.928387</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.768969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>US00185AAG94</td>\n",
       "      <td>30.539427</td>\n",
       "      <td>20.457131</td>\n",
       "      <td>10.082296</td>\n",
       "      <td>30.035312</td>\n",
       "      <td>20.961246</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-11.451835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>US00185AAH77</td>\n",
       "      <td>32.325171</td>\n",
       "      <td>21.928792</td>\n",
       "      <td>10.396380</td>\n",
       "      <td>31.805352</td>\n",
       "      <td>22.448611</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.069176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            isin  g_diff_max  g_diff_min      delta    perc_95   bottom_5  \\\n",
       "0   US001055AJ19    9.742960   -1.871478  11.614438   9.162238  -1.290756   \n",
       "1   US001055AL64   14.656741    0.554859  14.101882  13.951647   1.259953   \n",
       "2   US001055AM48   17.761705   -0.628311  18.390016  16.842204   0.291190   \n",
       "7   US00108WAD20   14.746628    0.342575  14.404053  14.026425   1.062777   \n",
       "9   US00108WAH34    6.722973   -6.687988  13.410961   6.052425  -6.017440   \n",
       "15  US001192AJ21   13.223852  -14.715790  27.939643  11.826870 -13.318808   \n",
       "16  US001192AK93    2.660700   -8.444020  11.104719   2.105464  -7.888784   \n",
       "21  US00185AAF12   23.268738    7.121001  16.147737  22.461351   7.928387   \n",
       "22  US00185AAG94   30.539427   20.457131  10.082296  30.035312  20.961246   \n",
       "23  US00185AAH77   32.325171   21.928792  10.396380  31.805352  22.448611   \n",
       "\n",
       "    cheap  rich  target_day  \n",
       "0       0     0    0.099140  \n",
       "1       0     1   -1.782996  \n",
       "2       1     0   26.010219  \n",
       "7       0     1  -13.939129  \n",
       "9       0     0   -5.382505  \n",
       "15      0     0   -6.692355  \n",
       "16      0     0   -4.071720  \n",
       "21      0     1    5.768969  \n",
       "22      0     1  -11.451835  \n",
       "23      0     1    4.069176  "
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker_final.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 816 bonds are cheap.\n"
     ]
    }
   ],
   "source": [
    "result_cheap = one_month_result_df[one_month_result_df['cheap']==1]\n",
    "print(\"There are\",result_cheap.shape[0], \"bonds are cheap.\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 838 bonds are rich.\n"
     ]
    }
   ],
   "source": [
    "result_rich = one_month_result_df[one_month_result_df['rich']==1]\n",
    "print(\"There are\",result_rich.shape[0], \"bonds are rich.\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further filter by subsector / bclass3 + S&P rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Insurance', 'Banking', 'Capital Goods', 'Electric',\n",
       "       'Consumer Cyclical', 'Basic Industry', 'Energy',\n",
       "       'Consumer Non-Cyclical', 'Technology', 'Other Industrial', 'REITs',\n",
       "       'Communications', 'Brokerage Assetmanagers Exchanges',\n",
       "       'Natural Gas', 'Transportation', 'Other Financial',\n",
       "       'Finance Companies', 'Other Utility'], dtype=object)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_month.bclass3.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_groupby = one_month.groupby(['bclass3','s&p_rating_num', 'date','isin'])['g_spd', 'years_to_mat'].mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.,  6.,  7.,  8.,  9., 10., 11., 13.,  4., 12.,  2.,  3., 21.,\n",
       "       23.])"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(sector_groupby.index.get_level_values(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1729)\n",
    "\n",
    "def func(x, m, c):\n",
    "    return m*np.log(x)+ c \n",
    "\n",
    "def cal_curve(sector_groupby):\n",
    "    \n",
    "    from scipy.optimize import curve_fit\n",
    "\n",
    "    sectors = pd.unique(sector_groupby.index.get_level_values(0))\n",
    "    ratings = pd.unique(sector_groupby.index.get_level_values(1))\n",
    "    dates = pd.unique(sector_groupby.index.get_level_values(2))\n",
    "    sector_temp = sector_groupby.reset_index()\n",
    "    \n",
    "    g_spd_pred =[]\n",
    "    diff = []\n",
    "    idx = []\n",
    "    \n",
    "    for s in sectors:\n",
    "        for r in ratings:\n",
    "            for d in dates:\n",
    "                temp = sector_temp[sector_temp['bclass3'] == s]\n",
    "                temp2 = temp[temp['s&p_rating_num'] == r]\n",
    "                sub_df = temp2[temp2['date'] == d]\n",
    "            \n",
    "                if sub_df.shape[0] >= 6:\n",
    "                    sub_x = sub_df['years_to_mat'].values\n",
    "                    sub_y = sub_df['g_spd'].values\n",
    "            \n",
    "                    popt, pcov = curve_fit(func, sub_x, sub_y)\n",
    "                    g_predict = func(sub_x, popt[0], popt[1])\n",
    "                    sub_diff = g_predict - sub_y\n",
    "                    g_spd_pred.append(g_predict)\n",
    "                    diff.append(sub_diff)\n",
    "                    idx.append(sub_df.index)\n",
    "            \n",
    "        g_pred = np.concatenate(g_spd_pred)\n",
    "        g_diff = np.concatenate(diff)\n",
    "        g_idx = np.concatenate(idx)\n",
    "    \n",
    "    return g_pred, g_diff, g_idx \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_peer_filter(peer_df, target_isin, target_date):\n",
    "    \n",
    "    avail_isin = np.intersect1d(target_isin, peer_df['isin'].values) \n",
    "    \n",
    "    prep_self = peer_df[peer_df['isin'].isin(avail_isin)]\n",
    "    self_df = prep_self.groupby(['isin'])[['g_diff']].max().reset_index()\n",
    "    self_df.columns = ['isin', 'g_diff_max']\n",
    "    \n",
    "    self_df['g_diff_min'] = prep_self.groupby(['isin'])[['g_diff']].min().values\n",
    "    self_df['delta'] = self_df['g_diff_max'] - self_df['g_diff_min']\n",
    "    self_df['perc_95'] = self_df.g_diff_min + self_df.delta.values*0.95\n",
    "    self_df['bottom_5'] = self_df.g_diff_min + self_df.delta.values*0.05\n",
    "   \n",
    "    # making sure delta is >= 10\n",
    "    delta_10 = self_df[self_df['delta']>=10]\n",
    "    delta_isin = delta_10['isin'].values\n",
    "    sub_peer = peer_df[peer_df['isin'].isin(delta_isin)]\n",
    "    \n",
    "    target_diff = sub_peer[sub_peer['date'] == target_date][['isin', 'g_diff']]  #1429 rows × 7 columns\n",
    "    sub_self = self_df[self_df['isin'].isin(target_diff['isin'].values)]\n",
    "    \n",
    "    return target_diff, sub_self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(target_diff, sub_self):\n",
    "    c = target_diff['g_diff'].values - sub_self['perc_95'].values\n",
    "    cheap =[1 if diff >0 else 0 for diff in c] \n",
    "    sub_self['cheap'] = cheap\n",
    "    \n",
    "    r = target_diff['g_diff'].values - sub_self['bottom_5'].values\n",
    "    rich = [1 if diff < 0 else 0 for diff in r]\n",
    "    sub_self['rich']= rich\n",
    "    \n",
    "    sub_self['target_day'] = target_diff['g_diff'].values\n",
    "    \n",
    "    return sub_self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_pred_s, g_diff_s, g_idx_s = cal_curve(sector_groupby)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_sector = sector_groupby.iloc[g_idx_s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AddisonYing/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "result_sector['g_pred'] = g_pred_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AddisonYing/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "result_sector['g_diff'] = g_diff_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(169379, 8)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peer_sector = result_sector.reset_index() \n",
    "peer_sector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target_isin = one_month[one_month['date'] == target_date]['isin'].values \n",
    "\n",
    "target_diff_s, sub_self_s = self_peer_filter(peer_sector, target_isin, target_date)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_final = get_results(target_diff_s, sub_self_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4286, 9)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sector_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1744"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sector_final.rich.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1707"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sector_final.cheap.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_isin_r = list(sector_final[sector_final['rich']==1]['isin'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_isin_c = list(sector_final[sector_final['cheap']==1]['isin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_isin_r = list(ticker_final[ticker_final['rich'] ==1]['isin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_isin_c = list(ticker_final[ticker_final['cheap'] ==1]['isin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "cheap_final = np.intersect1d(sector_isin_c, ticker_isin_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "rich_final = np.intersect1d(sector_isin_r, ticker_isin_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "471"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cheap_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "442"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rich_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Elin's results with Addy's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "elin = pd.read_csv('elin.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "elin_rich = elin['Rich bonds'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "elin_cheap = elin['Cheap bonds'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 47 rich bonds of the target date: 2019-03-07\n"
     ]
    }
   ],
   "source": [
    "elin_addy_rich = np.intersect1d(elin_rich, rich_final)\n",
    "print( \"There are\", len(elin_addy_rich), \"rich bonds of the target date:\", target_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 50 cheap bonds of the target date: 2019-03-07\n"
     ]
    }
   ],
   "source": [
    "elin_addy_cheap = np.intersect1d(elin_cheap, cheap_final)\n",
    "print( \"There are\", len(elin_addy_cheap), \"cheap bonds of the target date:\", target_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
